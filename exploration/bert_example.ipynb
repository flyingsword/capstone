{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4136bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-27 02:15:29.192857: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64\n",
      "2022-04-27 02:15:29.192923: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.models import Model\n",
    "from bert.tokenization.bert_tokenization import FullTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "386bf082",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-27 02:16:35.892125: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2022-04-27 02:16:35.961881: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-27 02:16:35.962385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.91GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-04-27 02:16:35.962442: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-27 02:16:35.963147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: \n",
      "pciBusID: 0000:02:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-04-27 02:16:35.963225: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64\n",
      "2022-04-27 02:16:35.963305: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64\n",
      "2022-04-27 02:16:35.963372: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64\n",
      "2022-04-27 02:16:35.982943: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2022-04-27 02:16:35.987924: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2022-04-27 02:16:35.988003: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64\n",
      "2022-04-27 02:16:35.988071: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64\n",
      "2022-04-27 02:16:35.988959: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-04-27 02:16:35.988971: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1766] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-04-27 02:16:35.989262: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-27 02:16:35.989602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-04-27 02:16:35.989617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      \n"
     ]
    }
   ],
   "source": [
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86f9bbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 128  # Your choice here.\n",
    "input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
    "                                       name=\"input_word_ids\")\n",
    "input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
    "                                   name=\"input_mask\")\n",
    "segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"segment_ids\")\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
    "                            trainable=True)\n",
    "pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f9972c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=[pooled_output, sequence_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84cfce70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_masks(tokens, max_seq_length):\n",
    "    \"\"\"Mask for padding\"\"\"\n",
    "    if len(tokens)>max_seq_length:\n",
    "        #Cutting down the excess length\n",
    "        tokens = tokens[0:max_seq_length]\n",
    "        return [1]*len(tokens)\n",
    "    else:\n",
    "        return [1]*len(tokens) + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "def get_segments(tokens, max_seq_length):\n",
    "    if len(tokens)>max_seq_length:\n",
    "        #Cutting down the excess length\n",
    "        tokens = tokens[:max_seq_length]\n",
    "        segments = []\n",
    "        current_segment_id = 0\n",
    "        for token in tokens:\n",
    "            segments.append(current_segment_id)\n",
    "            if token == \"[SEP]\":\n",
    "                current_segment_id = 1\n",
    "        return segments\n",
    "    else:\n",
    "        segments = []\n",
    "        current_segment_id = 0\n",
    "        for token in tokens:\n",
    "            segments.append(current_segment_id)\n",
    "            if token == \"[SEP]\":\n",
    "                current_segment_id = 1\n",
    "        return segments + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "def get_ids(tokens, tokenizer, max_seq_length):    \n",
    "    if len(tokens)>max_seq_length:\n",
    "        tokens = tokens[:max_seq_length]\n",
    "        token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        return token_ids\n",
    "    else:\n",
    "        token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n",
    "        return input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a869029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep(s, get = 'id'):\n",
    "    stokens = tokenizer.tokenize(s)\n",
    "    stokens = [\"[CLS]\"] + stokens + [\"[SEP]\"]\n",
    "    if get == 'id':\n",
    "        input_ids = get_ids(stokens, tokenizer, max_seq_length)\n",
    "        return input_ids\n",
    "    elif get == 'mask':\n",
    "        input_masks = get_masks(stokens, max_seq_length)\n",
    "        return input_masks\n",
    "    else:\n",
    "        input_segments = get_segments(stokens, max_seq_length)\n",
    "        return input_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1dd60927",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = FullTokenizer(vocab_file, do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2922bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDS # len: 128  :::  [101, 2021, 1996, 2087, 9145, 2001, 1996, 4121, 23163, 1999, 7408, 3318, 1010, 4895, 26362, 1997, 2426, 2797, 4753, 18496, 2545, 1012, 7687, 1010, 2009, 2965, 2008, 2748, 2924, 2165, 2009, 2005, 4379, 2008, 9883, 2006, 14336, 5414, 9144, 2097, 2022, 3825, 1998, 14729, 2005, 2039, 12792, 2006, 2049, 2808, 1012, 2004, 17781, 2545, 2357, 12398, 2545, 1010, 1996, 9883, 5079, 2000, 2122, 5414, 9144, 3062, 2125, 1996, 15288, 1012, 12267, 2038, 2085, 18152, 2000, 5670, 2000, 1037, 13726, 9529, 3218, 1997, 16095, 3775, 6774, 7408, 3318, 2738, 2084, 21725, 2122, 2039, 12792, 1012, 12267, 1521, 1055, 2693, 2000, 2273, 2094, 2627, 3971, 2965, 2008, 2045, 2097, 2022, 2053, 11808, 20096, 1999, 1996, 2925, 1012, 2023, 2003, 2204, 2739, 6195, 2008, 9387, 2293, 1037, 4550, 3746, 1998, 8840]\n",
      "MASKS # len: 128  :::  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "SEGEMNTS # len: 128  :::  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "#TESTING\n",
    "max_seq_length = 128  #This number will determine the number of tokens\n",
    " \n",
    "#An example for tokenization\n",
    "s1 = \"But the most painful was the huge reversal in fee income, unheard of among private sector lenders. Essentially, it means that Yes Bank took it for granted that fees on structured loan deals will be paid and accounted for upfront on its books. As borrowers turned defaulters, the fees tied to these loan deals fell off the cracks. Gill has now vowed to shift to a safer accounting practice of amortizing fee income rather than booking these upfront. Gill’s move to mend past ways means that there will be no nasty surprises in the future. This is good news considering that investors love a clean image and loathe uncertainties.But there is no gain without pain and the promise of a strong and stable balance sheet comes with some sacrifices as well. Investors will have to give up the hopes of phenomenal growth, a promise made by Kapoor.\"\n",
    "#s1 = train['STORY'].iloc[0]\n",
    "stokens1 = tokenizer.tokenize(s1)\n",
    "stokens1 = [\"[CLS]\"] + stokens1 + [\"[SEP]\"]\n",
    " \n",
    "input_ids1 = get_ids(stokens1, tokenizer, max_seq_length)\n",
    "input_masks1 = get_masks(stokens1, max_seq_length)\n",
    "input_segments1 = get_segments(stokens1, max_seq_length)\n",
    " \n",
    "print(\"IDS # len:\" , len(input_ids1), \" ::: \",input_ids1)\n",
    "print(\"MASKS # len:\" , len(input_masks1), \" ::: \",input_masks1)\n",
    "print(\"SEGEMNTS # len:\" , len(input_segments1), \" ::: \",input_segments1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fd5f60dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids1_tf = tf.convert_to_tensor(input_ids1)\n",
    "input_masks1_tf = tf.convert_to_tensor(input_masks1)\n",
    "input_segments1_tf = tf.convert_to_tensor(input_segments1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "22bfec1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_embs, all_embs = model.predict([input_ids1_tf, input_masks1_tf, input_segments1_tf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2590c680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.7348337 ,  0.12700568,  0.5870974 , ...,  0.54593676,\n",
       "        -0.47063637,  0.80095446],\n",
       "       [-0.30164298,  0.02687909,  0.67716587, ...,  0.6470015 ,\n",
       "        -0.5090403 ,  0.48810825],\n",
       "       [-0.38624573,  0.20944679,  0.57931405, ...,  0.75650096,\n",
       "        -0.28002295,  0.33652538],\n",
       "       ...,\n",
       "       [-0.13146849, -0.22396435,  0.21836293, ..., -0.6283861 ,\n",
       "         0.08465796,  0.28880864],\n",
       "       [-0.19912848,  0.24072008, -0.37078485, ..., -0.57031006,\n",
       "        -0.13679793,  0.7908602 ],\n",
       "       [-0.34718457, -0.09375188,  0.69986916, ...,  0.5418732 ,\n",
       "        -0.5776768 ,  0.79960287]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool_embs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b6de3abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 1, 768)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ba89056c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'but',\n",
       " 'the',\n",
       " 'most',\n",
       " 'painful',\n",
       " 'was',\n",
       " 'the',\n",
       " 'huge',\n",
       " 'reversal',\n",
       " 'in',\n",
       " 'fee',\n",
       " 'income',\n",
       " ',',\n",
       " 'un',\n",
       " '##heard',\n",
       " 'of',\n",
       " 'among',\n",
       " 'private',\n",
       " 'sector',\n",
       " 'lend',\n",
       " '##ers',\n",
       " '.',\n",
       " 'essentially',\n",
       " ',',\n",
       " 'it',\n",
       " 'means',\n",
       " 'that',\n",
       " 'yes',\n",
       " 'bank',\n",
       " 'took',\n",
       " 'it',\n",
       " 'for',\n",
       " 'granted',\n",
       " 'that',\n",
       " 'fees',\n",
       " 'on',\n",
       " 'structured',\n",
       " 'loan',\n",
       " 'deals',\n",
       " 'will',\n",
       " 'be',\n",
       " 'paid',\n",
       " 'and',\n",
       " 'accounted',\n",
       " 'for',\n",
       " 'up',\n",
       " '##front',\n",
       " 'on',\n",
       " 'its',\n",
       " 'books',\n",
       " '.',\n",
       " 'as',\n",
       " 'borrow',\n",
       " '##ers',\n",
       " 'turned',\n",
       " 'default',\n",
       " '##ers',\n",
       " ',',\n",
       " 'the',\n",
       " 'fees',\n",
       " 'tied',\n",
       " 'to',\n",
       " 'these',\n",
       " 'loan',\n",
       " 'deals',\n",
       " 'fell',\n",
       " 'off',\n",
       " 'the',\n",
       " 'cracks',\n",
       " '.',\n",
       " 'gill',\n",
       " 'has',\n",
       " 'now',\n",
       " 'vowed',\n",
       " 'to',\n",
       " 'shift',\n",
       " 'to',\n",
       " 'a',\n",
       " 'safer',\n",
       " 'accounting',\n",
       " 'practice',\n",
       " 'of',\n",
       " 'amor',\n",
       " '##ti',\n",
       " '##zing',\n",
       " 'fee',\n",
       " 'income',\n",
       " 'rather',\n",
       " 'than',\n",
       " 'booking',\n",
       " 'these',\n",
       " 'up',\n",
       " '##front',\n",
       " '.',\n",
       " 'gill',\n",
       " '’',\n",
       " 's',\n",
       " 'move',\n",
       " 'to',\n",
       " 'men',\n",
       " '##d',\n",
       " 'past',\n",
       " 'ways',\n",
       " 'means',\n",
       " 'that',\n",
       " 'there',\n",
       " 'will',\n",
       " 'be',\n",
       " 'no',\n",
       " 'nasty',\n",
       " 'surprises',\n",
       " 'in',\n",
       " 'the',\n",
       " 'future',\n",
       " '.',\n",
       " 'this',\n",
       " 'is',\n",
       " 'good',\n",
       " 'news',\n",
       " 'considering',\n",
       " 'that',\n",
       " 'investors',\n",
       " 'love',\n",
       " 'a',\n",
       " 'clean',\n",
       " 'image',\n",
       " 'and',\n",
       " 'lo',\n",
       " '##ath',\n",
       " '##e',\n",
       " 'uncertain',\n",
       " '##ties',\n",
       " '.',\n",
       " 'but',\n",
       " 'there',\n",
       " 'is',\n",
       " 'no',\n",
       " 'gain',\n",
       " 'without',\n",
       " 'pain',\n",
       " 'and',\n",
       " 'the',\n",
       " 'promise',\n",
       " 'of',\n",
       " 'a',\n",
       " 'strong',\n",
       " 'and',\n",
       " 'stable',\n",
       " 'balance',\n",
       " 'sheet',\n",
       " 'comes',\n",
       " 'with',\n",
       " 'some',\n",
       " 'sacrifices',\n",
       " 'as',\n",
       " 'well',\n",
       " '.',\n",
       " 'investors',\n",
       " 'will',\n",
       " 'have',\n",
       " 'to',\n",
       " 'give',\n",
       " 'up',\n",
       " 'the',\n",
       " 'hopes',\n",
       " 'of',\n",
       " 'phenomena',\n",
       " '##l',\n",
       " 'growth',\n",
       " ',',\n",
       " 'a',\n",
       " 'promise',\n",
       " 'made',\n",
       " 'by',\n",
       " 'kapoor',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stokens1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a55d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
